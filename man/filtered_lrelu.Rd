% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/filtered_lrelu.R
\name{filtered_lrelu}
\alias{filtered_lrelu}
\title{Filtered leaky ReLU for a batch of 2D images.}
\usage{
filtered_lrelu(
  x,
  fu = NULL,
  fd = NULL,
  b = NULL,
  up = 1,
  down = 1,
  padding = 0,
  gain = sqrt(2),
  slope = 0.2,
  clamp = NULL,
  flip_filter = FALSE,
  impl = if (cuda_is_available()) "cuda" else "ref"
)
}
\arguments{
\item{x}{Float32/float16/float64 input tensor of the shape
\code{c(batch_size, num_channels, in_height, in_width)}.}

\item{fu}{Float32 upsampling FIR filter of the shape
\code{c(filter_height, filter_width)} (non-separable),
\code{filter_taps} (separable), or \code{NULL} (identity).}

\item{fd}{Float32 downsampling FIR filter of the shape
\code{c(filter_height, filter_width)} (non-separable),
\code{filter_taps} (separable), or \code{NULL} (identity).}

\item{b}{Bias vector, or \code{NULL} to disable. Must be a 1D tensor of the same type
as \code{x}. The length of vector must must match the channel dimension of \code{x}.}

\item{up}{Integer upsampling factor. Can be a single integer or a vector of integers
\code{c(x, y)} (default: 1).}

\item{down}{Integer downsampling factor. Can be a single int or a vector
\code{c(x, y)} (default: 1).}

\item{padding}{Padding with respect to the upsampled image. Can be a single number
or a vector \code{c(x, y)} or \code{c(x_before, x_after, y_before, y_after)}
(default: 0).}

\item{gain}{Overall scaling factor for signal magnitude (default: 1).}

\item{slope}{Slope on the negative side of leaky ReLU (default: 0.2).}

\item{clamp}{Maximum magnitude for leaky ReLU output (default: NULL).}

\item{flip_filter}{\code{FALSE} = convolution, \code{TRUE} = correlation (default: \code{FALSE}).}

\item{impl}{Implementation to use. Can be \code{'ref'} or \code{'cuda'}
(default: \code{'cuda'} if \code{torch::cuda_is_available() == TRUE}, \code{'ref'} otherwise).}
}
\value{
Tensor of the shape \code{c(batch_size, num_channels, out_height, out_width)}.
}
\description{
Performs the following sequence of operations for each channel:
\enumerate{
\item Add channel-specific bias if provided (\code{b}).
\item Upsample the image by inserting N-1 zeros after each pixel (\code{up}).
\item Pad the image with the specified number of zeros on each side (\code{padding}).
Negative padding corresponds to cropping the image.
\item Convolve the image with the specified upsampling FIR filter (\code{fu}), shrinking it
so that the footprint of all output pixels lies within the input image.
\item Multiply each value by the provided gain factor (\code{gain}).
\item Apply leaky ReLU activation function to each value.
\item Clamp each value between -clamp and +clamp, if \code{clamp} parameter is provided.
\item Convolve the image with the specified downsampling FIR filter (\code{fd}), shrinking
it so that the footprint of all output pixels lies within the input image.
\item Downsample the image by keeping every Nth pixel (\code{down}).
The fused op is considerably more efficient than performing the same calculation
using standard PyTorch ops. It supports gradients of arbitrary order.
}
}
